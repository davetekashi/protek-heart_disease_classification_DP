{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81c0d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a0feebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\hp\\Desktop\\heart.csv')\n",
    "\n",
    "# Split the data into training and testing\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Create a custom early stoppinng callback that stops training the model after the accuracy is 100%\n",
    "# The custom callback is from tensorflow.keras.callbacks.Callback\n",
    "class MyThresholdCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, threshold):\n",
    "        super(MyThresholdCallback, self).__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None): \n",
    "        accuracy = logs[\"val_binary_accuracy\"]\n",
    "        if accuracy >= self.threshold:\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "            \n",
    "early_stopping = MyThresholdCallback(threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "062d904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 15s 84ms/step - loss: 0.4673 - binary_accuracy: 0.8207 - val_loss: 0.5560 - val_binary_accuracy: 0.7854\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 2s 52ms/step - loss: 0.1918 - binary_accuracy: 0.9280 - val_loss: 0.7661 - val_binary_accuracy: 0.5122\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 1s 44ms/step - loss: 0.1734 - binary_accuracy: 0.9329 - val_loss: 0.5418 - val_binary_accuracy: 0.7610\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 0.1065 - binary_accuracy: 0.9524 - val_loss: 0.4890 - val_binary_accuracy: 0.7122\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 1s 42ms/step - loss: 0.0901 - binary_accuracy: 0.9646 - val_loss: 0.3949 - val_binary_accuracy: 0.8341\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.0924 - binary_accuracy: 0.9683 - val_loss: 0.3816 - val_binary_accuracy: 0.8390\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 2s 46ms/step - loss: 0.1078 - binary_accuracy: 0.9585 - val_loss: 0.3329 - val_binary_accuracy: 0.8390\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 1s 45ms/step - loss: 0.0960 - binary_accuracy: 0.9659 - val_loss: 0.2920 - val_binary_accuracy: 0.8732\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.0620 - binary_accuracy: 0.9817 - val_loss: 0.1299 - val_binary_accuracy: 0.9610\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.0530 - binary_accuracy: 0.9829 - val_loss: 0.1022 - val_binary_accuracy: 0.9854\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 2s 46ms/step - loss: 0.0501 - binary_accuracy: 0.9817 - val_loss: 0.0950 - val_binary_accuracy: 0.9756\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 1s 43ms/step - loss: 0.0639 - binary_accuracy: 0.9780 - val_loss: 0.0389 - val_binary_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Create the model with 4 dense layers (dense layers contain our neurons)\n",
    "# The model uses BatchNormilzation() in order to scale our data in the range: [0, 1]\n",
    "model = keras.Sequential([\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1024, activation='relu', input_shape=[X.shape[1]]),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "#  I Compiled the model using adam optimizer\n",
    "# I Measured the loss with binary_crossentropy\n",
    "# Set metrics to binary_accuracy, which lets us know how accurate the model is\n",
    "# The accuracy lies on a scale of [0.0, 1.0],\n",
    "# In order to convert this accuracy to percentage, move the decimal point to the right twice (acc*100)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "# Finally fit the model, training it with X_train and y_train, and validating it with X_test and y_test\n",
    "# Use 25 data points per epoch (the amount of epochs is the amount of times we feed the model data)\n",
    "# Use the custom callback defined earlier that stops the model at 100% accuracy\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=25,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62dfda27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot our increase/decrease in percentage and loss\n",
    "# The left graph represents percent, and the right graph represents loss\n",
    "# i'm looking for a high percent and a low loss\n",
    "#history_df = pd.DataFrame(history.history)\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "#f.figure.set_figheight(5)\n",
    "#f.figure.set_figwidth(15)\n",
    "\n",
    "ax1.plot(history_df.index, history_df['binary_accuracy'])\n",
    "ax1.plot(history_df.index, history_df['val_binary_accuracy'])\n",
    "\n",
    "ax2.plot(history_df.index, history_df['loss'])\n",
    "ax2.plot(history_df.index, history_df['val_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
